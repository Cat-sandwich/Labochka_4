{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import os.path\n",
    "import pymorphy2\n",
    "import regex as re\n",
    "import main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пункт 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Метка класса                                       Текст отзыва\n",
      "0            good  Зеленая миля\\n'Они помогли ему убить себя и та...\n",
      "1            good  Зеленая миля\\n'Боже, иногда Зеленая миля так д...\n",
      "2            good  Зеленая миля\\nОни помогли ему убить себя\\n\\n«О...\n",
      "3            good  Зеленая миля\\n«Когда призовет Господь на свой ...\n",
      "4            good  Зеленая миля\\nОбвиненный в страшном преступлен...\n",
      "...           ...                                                ...\n",
      "1995          bad  Сумерки\\nФильм «ни о чем»! Не понимаю, что мно...\n",
      "1996          bad  Сумерки\\nСначала был Макс Шрек.\\n\\n\\nПотом Бел...\n",
      "1997          bad  Сумерки\\nНа экраны вышла первая часть вампирск...\n",
      "1998          bad  Сумерки\\nСемнадцатилетняя Белла Свон переезжае...\n",
      "1999          bad  Сумерки\\nМоё отношение к данному фильму весьма...\n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "column_name = ['Метка класса', 'Текст отзыва', 'Количество слов']\n",
    "reviews_df = main.add_to_dataframe()\n",
    "print(reviews_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пункт 2 сделан сразу в пункте 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пункт 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Столбец: < Метка класса > пустой? - False\n",
      "Столбец: < Текст отзыва > пустой? - False\n"
     ]
    }
   ],
   "source": [
    "print('Столбец: <', column_name[0], '> пустой? -',\n",
    "          main.check_nan(reviews_df, column_name[0]))\n",
    "print('Столбец: <', column_name[1], '> пустой? -',\n",
    "        main.check_nan(reviews_df, column_name[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пункт 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Метка класса                                       Текст отзыва  \\\n",
      "0            good  Зеленая миля\\n'Они помогли ему убить себя и та...   \n",
      "1            good  Зеленая миля\\n'Боже, иногда Зеленая миля так д...   \n",
      "2            good  Зеленая миля\\nОни помогли ему убить себя\\n\\n«О...   \n",
      "3            good  Зеленая миля\\n«Когда призовет Господь на свой ...   \n",
      "4            good  Зеленая миля\\nОбвиненный в страшном преступлен...   \n",
      "...           ...                                                ...   \n",
      "1995          bad  Сумерки\\nФильм «ни о чем»! Не понимаю, что мно...   \n",
      "1996          bad  Сумерки\\nСначала был Макс Шрек.\\n\\n\\nПотом Бел...   \n",
      "1997          bad  Сумерки\\nНа экраны вышла первая часть вампирск...   \n",
      "1998          bad  Сумерки\\nСемнадцатилетняя Белла Свон переезжае...   \n",
      "1999          bad  Сумерки\\nМоё отношение к данному фильму весьма...   \n",
      "\n",
      "      Количество слов  \n",
      "0                 117  \n",
      "1                1448  \n",
      "2                 639  \n",
      "3                 751  \n",
      "4                 361  \n",
      "...               ...  \n",
      "1995              176  \n",
      "1996              609  \n",
      "1997              346  \n",
      "1998              195  \n",
      "1999              327  \n",
      "\n",
      "[2000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "count_word = main.count_words_in_text(reviews_df, column_name[1])\n",
    "reviews_df[column_name[2]] = pd.Series(count_word)\n",
    "print(reviews_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пункт 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    2000.000000\n",
      "mean      378.286500\n",
      "std       221.887488\n",
      "min        13.000000\n",
      "25%       215.000000\n",
      "50%       324.000000\n",
      "75%       486.500000\n",
      "max      2427.000000\n",
      "Name: Количество слов, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "stat = main.statistical_information(reviews_df, column_name[2])\n",
    "print(stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пункт 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Метка класса                                       Текст отзыва  \\\n",
      "81           good  Зеленая миля\\nПотрясающе!Просто потрясающе!\\n\\...   \n",
      "253          good  Список Шиндлера\\nПросто посмотри - и уже никог...   \n",
      "630          good  Назад в будущее 2\\nГениальный фильм. Один из т...   \n",
      "643          good  Назад в будущее 2\\n2-я часть самая лучшая! Зде...   \n",
      "660          good  Назад в будущее 2\\nОтличный фильм, прерасное д...   \n",
      "1555          bad  Матрица\\nПобег в реальность не удалсяСпецэффек...   \n",
      "1720          bad  Ночной дозор\\nГолливуд пока впередиСлабый филь...   \n",
      "\n",
      "      Количество слов  \n",
      "81                 50  \n",
      "253                13  \n",
      "630                26  \n",
      "643                26  \n",
      "660                42  \n",
      "1555               49  \n",
      "1720               49  \n"
     ]
    }
   ],
   "source": [
    "filtered_reviews_df = main.filtered_dataframe_word(\n",
    "        reviews_df, column_name[2], 50)\n",
    "print(filtered_reviews_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пункт 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Метка класса                                       Текст отзыва\n",
      "0           good  Зеленая миля\\n'Они помогли ему убить себя и та...\n",
      "1           good  Зеленая миля\\n'Боже, иногда Зеленая миля так д...\n",
      "2           good  Зеленая миля\\nОни помогли ему убить себя\\n\\n«О...\n",
      "3           good  Зеленая миля\\n«Когда призовет Господь на свой ...\n",
      "4           good  Зеленая миля\\nОбвиненный в страшном преступлен...\n",
      "..           ...                                                ...\n",
      "995         good  1+1\\nЯ, честно, до появления этого фильма в то...\n",
      "996         good  1+1\\nДрузья давно советовали мне посмотреть эт...\n",
      "997         good  1+1\\nВсегда, когда смотришь хороший европейски...\n",
      "998         good  1+1\\nПосмотрел этот фильм сравнительно недавно...\n",
      "999         good  Тайна Коко\\nЭто надо видеть!!!Наверное, это бу...\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "reviews_good_df = main.filtered_dataframe_class(\n",
    "        reviews_df, column_name[0], 'good')\n",
    "\n",
    "    \n",
    "print(reviews_good_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пункт 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Для положительных отзывов:\n",
      "\n",
      "Минимальное кол-во слов: 13.0\n",
      "Максимальное кол-во слов: 2427.0\n",
      "Среднее кол-во слов: 370.85\n",
      "\n",
      "Для отрицательных отзывов:\n",
      "\n",
      "Минимальное кол-во слов: 49.0\n",
      "Максимальное кол-во слов: 1015.0\n",
      "Среднее кол-во слов: 385.723\n"
     ]
    }
   ],
   "source": [
    "stat_good = main.statistical_information(reviews_good_df, column_name[2])\n",
    "print('\\nДля положительных отзывов:\\n')\n",
    "print('Минимальное кол-во слов:', stat_good['min'])\n",
    "print('Максимальное кол-во слов:', stat_good['max'])\n",
    "print('Среднее кол-во слов:', stat_good['mean'])\n",
    "\n",
    "reviews_bad_df = main.filtered_dataframe_class(reviews_df, column_name[0], 'bad')\n",
    "\n",
    "stat_bad = main.statistical_information(reviews_bad_df, column_name[2])\n",
    "print('\\nДля отрицательных отзывов:\\n')\n",
    "print('Минимальное кол-во слов:', stat_bad['min'])\n",
    "print('Максимальное кол-во слов:', stat_bad['max'])\n",
    "print('Среднее кол-во слов:', stat_bad['mean'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для лемматизации слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lemma_list \u001b[39m=\u001b[39m main\u001b[39m.\u001b[39;49mlemmatizer_list(reviews_good_df, column_name[\u001b[39m1\u001b[39;49m], \u001b[39m'\u001b[39;49m\u001b[39mgood\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mКоличество слов: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(lemma_list))\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mfinally\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nika\\Desktop\\python\\Labochka_4\\main.py:54\u001b[0m, in \u001b[0;36mlemmatizer_list\u001b[1;34m(reviews_df, column_name, class_name)\u001b[0m\n\u001b[0;32m     52\u001b[0m word \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mpL\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mp\u001b[39m\u001b[39m{Space}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, word)\u001b[39m.\u001b[39mlower()\n\u001b[0;32m     53\u001b[0m \u001b[39m# print(pymorphy2.MorphAnalyzer().parse(word)[0].tag.POS)\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m part_speech \u001b[39m=\u001b[39m pymorphy2\u001b[39m.\u001b[39;49mMorphAnalyzer()\u001b[39m.\u001b[39mparse(word)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtag\u001b[39m.\u001b[39mPOS\n\u001b[0;32m     55\u001b[0m \u001b[39mif\u001b[39;00m part_speech \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m functors_pos:\n\u001b[0;32m     56\u001b[0m     \u001b[39m# print(word)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     output_lemma\u001b[39m.\u001b[39mappend(lemma\u001b[39m.\u001b[39mparse(word)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnormal_form)\n",
      "File \u001b[1;32mc:\\Users\\nika\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pymorphy2\\analyzer.py:203\u001b[0m, in \u001b[0;36mMorphAnalyzer.__init__\u001b[1;34m(self, path, lang, result_type, units, probability_estimator_cls, char_substitutes)\u001b[0m\n\u001b[0;32m    200\u001b[0m path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchoose_dictionary_path(path, lang)\n\u001b[0;32m    202\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m--> 203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdictionary \u001b[39m=\u001b[39m opencorpora_dict\u001b[39m.\u001b[39;49mDictionary(path)\n\u001b[0;32m    204\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlang \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchoose_language(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdictionary, lang)\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprob_estimator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_prob_estimator(\n\u001b[0;32m    207\u001b[0m         probability_estimator_cls, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdictionary, path\n\u001b[0;32m    208\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\nika\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pymorphy2\\opencorpora_dict\\wrapper.py:18\u001b[0m, in \u001b[0;36mDictionary.__init__\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, path):\n\u001b[0;32m     16\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mLoading dictionaries from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, path)\n\u001b[1;32m---> 18\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data \u001b[39m=\u001b[39m load_dict(path)\n\u001b[0;32m     20\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mformat: \u001b[39m\u001b[39m%(format_version)s\u001b[39;00m\u001b[39m, revision: \u001b[39m\u001b[39m%(source_revision)s\u001b[39;00m\u001b[39m, updated: \u001b[39m\u001b[39m%(compiled_at)s\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data\u001b[39m.\u001b[39mmeta)\n\u001b[0;32m     22\u001b[0m     \u001b[39m# attributes from opencorpora_dict.storage.LoadedDictionary\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nika\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pymorphy2\\opencorpora_dict\\storage.py:57\u001b[0m, in \u001b[0;36mload_dict\u001b[1;34m(path, gramtab_format)\u001b[0m\n\u001b[0;32m     54\u001b[0m str_gramtab \u001b[39m=\u001b[39m _load_gramtab(meta, gramtab_format, path)\n\u001b[0;32m     55\u001b[0m gramtab \u001b[39m=\u001b[39m [Tag(tag_str) \u001b[39mfor\u001b[39;00m tag_str \u001b[39min\u001b[39;00m str_gramtab]\n\u001b[1;32m---> 57\u001b[0m suffixes \u001b[39m=\u001b[39m json_read(_f(\u001b[39m'\u001b[39;49m\u001b[39msuffixes.json\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m     58\u001b[0m paradigms \u001b[39m=\u001b[39m _load_paradigms(_f(\u001b[39m'\u001b[39m\u001b[39mparadigms.array\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     59\u001b[0m words \u001b[39m=\u001b[39m dawg\u001b[39m.\u001b[39mWordsDawg()\u001b[39m.\u001b[39mload(_f(\u001b[39m'\u001b[39m\u001b[39mwords.dawg\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\nika\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pymorphy2\\opencorpora_dict\\storage.py:47\u001b[0m, in \u001b[0;36mload_dict.<locals>.<lambda>\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_dict\u001b[39m(path, gramtab_format\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mopencorpora-int\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     42\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[39m    Load pymorphy2 dictionary.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39m    ``path`` is a folder name with dictionary data.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m     _f \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m p: os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(path, p)\n\u001b[0;32m     49\u001b[0m     meta \u001b[39m=\u001b[39m load_meta(_f(\u001b[39m'\u001b[39m\u001b[39mmeta.json\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     50\u001b[0m     _assert_format_is_compatible(meta, path)\n",
      "File \u001b[1;32mc:\\Users\\nika\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ntpath.py:105\u001b[0m, in \u001b[0;36mjoin\u001b[1;34m(path, *paths)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjoin\u001b[39m(path, \u001b[39m*\u001b[39mpaths):\n\u001b[0;32m    104\u001b[0m     path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(path)\n\u001b[1;32m--> 105\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39;49m(path, \u001b[39mbytes\u001b[39;49m):\n\u001b[0;32m    106\u001b[0m         sep \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    107\u001b[0m         seps \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lemma_list = main.lemmatizer_list(reviews_good_df, column_name[1], 'good')\n",
    "print('Количество слов: ' + len(lemma_list))\n",
    "print('finally')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1af5a1ec5683947446bd5f176e49a8bdacde1661c6109a52b4e2c5a12da96685"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
